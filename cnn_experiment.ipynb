{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUNTARY NEURAL NETWORK\n",
    "The goal of this notebook is to understand the CNN architexture and implement it from scratch with numpy and JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, input_shape, num_filters, filter_size, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the CNN.\n",
    "        \n",
    "        Parameters:\n",
    "        - input_shape: tuple(int, int)\n",
    "            Shape of the input images (height, width).\n",
    "            Example: (28, 28) for a 28x28 grayscale image.\n",
    "            \n",
    "        - num_filters: int\n",
    "            Number of filters in the convolutional layer.\n",
    "            Example: 3 for three filters.\n",
    "            \n",
    "        - filter_size: int\n",
    "            Height and width of each filter in the convolutional layer.\n",
    "            Filters are square matrices.\n",
    "            Example: 3 for a 3x3 filter.\n",
    "            \n",
    "        - num_classes: int\n",
    "            Number of output classes in the classification task.\n",
    "            Example: 10 for digit classification (0 to 9).\n",
    "            \n",
    "        -- Example usage:\n",
    "        cnn = CNN(input_shape=(28, 28), num_filters=3, filter_size=3, num_classes=10)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "        # Initializing filters randomly\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / filter_size**2\n",
    "        \n",
    "        # Initializing weights for the fully connected layer\n",
    "        output_size_after_conv = input_shape[0] - filter_size + 1  # Considering stride=1 and no padding\n",
    "        self.fc_weights = np.random.randn(output_size_after_conv**2 * num_filters, num_classes) / output_size_after_conv**2\n",
    "        \n",
    "    def convolution(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform convolution operation on the input using the filters.\n",
    "        \n",
    "        Parameters:\n",
    "        - inputs: ndarray\n",
    "            Input images to perform convolution on. \n",
    "            Shape: (input_height, input_width)\n",
    "            \n",
    "        Returns:\n",
    "        - outputs: ndarray\n",
    "            Feature maps after applying convolution.\n",
    "            Shape: (output_height, output_width, num_filters)\n",
    "        \"\"\"\n",
    "        \n",
    "        input_height, input_width = inputs.shape\n",
    "        output_height = input_height - self.filter_size + 1\n",
    "        output_width = input_width - self.filter_size + 1\n",
    "        \n",
    "        outputs = np.zeros((output_height, output_width, self.num_filters))\n",
    "    \n",
    "        for i in range(output_height):\n",
    "            for j in range(output_width):\n",
    "                for k in range(self.num_filters):\n",
    "                    outputs[i, j, k] = np.sum(inputs[i:i+self.filter_size, j:j+self.filter_size] * self.filters[k])\n",
    "                    \n",
    "        return outputs\n",
    "    \n",
    "    def relu(self, inputs):\n",
    "        \"\"\"\n",
    "        Apply the ReLU activation function element-wise to the inputs.\n",
    "        \n",
    "        Parameters:\n",
    "        - inputs: ndarray\n",
    "            Input values to apply the activation function on.\n",
    "            Shape: (height, width, depth)\n",
    "            \n",
    "        Returns:\n",
    "        - outputs: ndarray\n",
    "            Outputs after applying the activation function.\n",
    "            Shape: (height, width, depth)\n",
    "        \"\"\"\n",
    "    \n",
    "        outputs = np.maximum(0, inputs)\n",
    "        return outputs\n",
    "    \n",
    "    def max_pooling(self, inputs, pool_size, strides):\n",
    "        # Perform max pooling operation here\n",
    "        pass\n",
    "    \n",
    "    def softmax(self, inputs):\n",
    "        # Apply softmax activation function here\n",
    "        pass\n",
    "    \n",
    "    def forward_pass(self, inputs):\n",
    "        # Implement the complete forward pass here\n",
    "        pass\n",
    "    \n",
    "    def compute_loss(self, predictions, labels):\n",
    "        # Compute the loss here\n",
    "        pass\n",
    "    \n",
    "    def backward_pass(self, d_loss, cache):\n",
    "        # Implement the complete backward pass here\n",
    "        pass\n",
    "        \n",
    "    def update_weights(self, learning_rate):\n",
    "        # Update weights using gradients computed in backward_pass\n",
    "        pass\n",
    "        \n",
    "    def train(self, inputs, labels, epochs, learning_rate):\n",
    "        # Implement the training loop here\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAXEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
